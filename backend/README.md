# Contract Clause Testing Lab - Backend

This is the backend API for the Contract Clause Testing Lab, providing LLM-powered clause comparison and analysis.

## ğŸ¯ Purpose

This is a **conflict detection and analysis lab**. Document parsing and clause extraction features have been removed and will be integrated separately later.

## ğŸ—ï¸ Architecture

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/v1/
â”‚   â”‚   â”œâ”€â”€ endpoints/
â”‚   â”‚   â”‚   â”œâ”€â”€ compare.py           # 1-to-1 clause comparison
â”‚   â”‚   â”‚   â”œâ”€â”€ batch_compare.py     # 1-to-N batch comparison
â”‚   â”‚   â”‚   â”œâ”€â”€ all_vs_all_compare.py # N-to-N with self-check
â”‚   â”‚   â”‚   â””â”€â”€ chat.py              # AI chatbot
â”‚   â”‚   â””â”€â”€ api.py                   # Router configuration
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ config.py                # App settings
â”‚   â”œâ”€â”€ services/                    # (empty - cleaned up)
â”‚   â”œâ”€â”€ utils/                       # Shared utilities
â”‚   â””â”€â”€ main.py                      # FastAPI entry point
â”œâ”€â”€ pyproject.toml                   # Dependencies
â””â”€â”€ Dockerfile                       # Container config
```

## âœ¨ Features

### 1. Single Clause Comparison (1â†’1)
**Endpoint:** `POST /api/v1/compare/clauses`

Compare two clauses with a custom prompt.

**Request:**
```json
{
  "clause_a": "Contract term A...",
  "clause_b": "Contract term B...",
  "prompt": "Compare these clauses for conflicts..."
}
```

**Response:**
```json
{
  "response": "Analysis from LLM...",
  "model": "qwen2.5:32b"
}
```

### 2. Batch Comparison (1â†’N)
**Endpoint:** `POST /api/v1/compare/batch`

Compare one clause against multiple clauses.

**Request:**
```json
{
  "reference_clause": "Main clause...",
  "clauses_to_compare": ["Clause 1...", "Clause 2...", "Clause 3..."],
  "prompt": "Check for conflicts..."
}
```

**Response:** Streams results via Server-Sent Events (SSE).

### 3. All-vs-All Comparison (Nâ†’N)
**Endpoint:** `POST /api/v1/compare/all-vs-all`

Compare all clauses against each other, including self-consistency checks.

**Request:**
```json
{
  "clauses": ["Clause 1...", "Clause 2...", "Clause N..."],
  "pair_prompt": "Compare these two clauses...",
  "self_prompt": "Check this clause for internal conflicts..."
}
```

**Features:**
- Generates N*(N+1)/2 comparisons (N self-checks + N*(N-1)/2 pairs)
- Concurrent processing with semaphore (2 parallel LLM calls)
- Batch processing (10 comparisons per batch)
- Real-time SSE streaming
- Robust conflict detection with 3-tier priority system

**Response:** Streams comparison results via SSE.

### 4. AI Chatbot
**Endpoint:** `POST /api/v1/chat/send`

Interactive chat with Qwen2.5 for clause analysis.

## ğŸ”§ Configuration

Set the following environment variables in `backend/.env`:

```bash
# LLM Configuration
OLLAMA_BASE_URL=http://51.112.105.60:11434
OLLAMA_MODEL=qwen2.5:32b

# API Configuration
API_V1_STR=/api/v1
PROJECT_NAME=Contract Clause Testing Lab
```

## ğŸš€ Running Locally

```bash
# Install dependencies
cd backend
pip install -e .

# Run server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

## ğŸ³ Docker

```bash
# Build
docker compose build api

# Run
docker compose up -d api
```

## ğŸ“Š Performance

- **Concurrent processing**: 2 parallel LLM calls (configurable via `MAX_CONCURRENT_LLM_CALLS`)
- **Batch size**: 10 comparisons per batch
- **Typical speed**: ~5 seconds per comparison (with 2x concurrency)
- **Conflict detection**: 3-tier priority system (structured format â†’ explicit phrases â†’ fallback)

## ğŸ”® Future Integration

This lab is designed to receive new parsing and extraction code. The clean modular structure allows easy integration of:
- Document parsers (PDF, DOCX, etc.)
- Clause extraction algorithms
- Storage and retrieval systems

## ğŸ› ï¸ Development Notes

- All database code has been removed (no models, CRUD, migrations)
- Document processing services removed
- Celery worker tasks removed
- Only LLM communication logic remains
- Clean, minimal codebase focused on comparison/analysis

## ğŸ“ API Documentation

Once running, visit:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc
